<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ResNet18 ONNX Web Inference</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
      }
      .result {
        margin-top: 20px;
        font-weight: bold;
      }
      #preview {
        max-width: 300px;
        margin-top: 10px;
      }
    </style>
  </head>
  <body>
    <h1>ResNet18 Image Classification</h1>
    <input type="file" id="imageInput" accept="image/*" />
    <div>
      <img id="preview" />
    </div>
    <div class="result" id="result"></div>

    <script type="module">
      // Initialize ONNX Runtime Web session
      let session;

      async function initONNX() {
        try {
          session = await ort.InferenceSession.create(
            "resnet18-quantized.onnx"
          );
          console.log("Model loaded successfully");
        } catch (e) {
          console.error("Failed to load ONNX model:", e);
        }
      }

      // Preprocess image to match ResNet18 input requirements
      async function preprocessImage(img) {
        const canvas = document.createElement("canvas");
        const ctx = canvas.getContext("2d");
        canvas.width = 224;
        canvas.height = 224;

        // Draw and resize image
        ctx.drawImage(img, 0, 0, 224, 224);
        const imageData = ctx.getImageData(0, 0, 224, 224).data;

        // Convert to float32 tensor, normalize to [0,1] and apply ImageNet normalization
        const tensor = new Float32Array(1 * 3 * 224 * 224);
        for (let i = 0; i < 224 * 224; i++) {
          const red = imageData[i * 4] / 255;
          const green = imageData[i * 4 + 1] / 255;
          const blue = imageData[i * 4 + 2] / 255;

          // CHW format
          tensor[i] = (red - 0.485) / 0.229;
          tensor[i + 224 * 224] = (green - 0.456) / 0.224;
          tensor[i + 2 * 224 * 224] = (blue - 0.406) / 0.225;
        }

        return tensor;
      }

      async function runInference(tensor) {
        const inputTensor = new ort.Tensor("float32", tensor, [1, 3, 224, 224]);
        const outputs = await session.run({ input: inputTensor });
        const scores = outputs["output"].data;
        return Array.from(scores).indexOf(Math.max(...scores));
      }

      // Handle image upload
      document
        .getElementById("imageInput")
        .addEventListener("change", async (e) => {
          const file = e.target.files[0];
          if (!file) return;

          // Display preview
          const img = new Image();
          img.src = URL.createObjectURL(file);
          img.onload = async () => {
            document.getElementById("preview").src = img.src;

            try {
              const tensor = await preprocessImage(img);
              const classIndex = await runInference(tensor);
              document.getElementById(
                "result"
              ).textContent = `Predicted Class: ${classIndex}`;
            } catch (error) {
              console.error("Inference failed:", error);
              document.getElementById("result").textContent =
                "Error running inference";
            }
          };
        });

      // Initialize ONNX Runtime when page loads
      initONNX();
    </script>
  </body>
</html>
